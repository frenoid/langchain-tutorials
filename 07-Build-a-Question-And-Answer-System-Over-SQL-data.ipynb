{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7035ad-cfea-4c2e-9cfe-c37942d8922d",
   "metadata": {},
   "source": [
    "# Build a Question and Answer system over SQL data\n",
    "Adapted from [Build a Question/Answering system over SQL data](https://python.langchain.com/v0.2/docs/tutorials/sql_qa/)\n",
    "\n",
    "Enabling a LLM system to query structured data can be qualitatively different from unstructured text data. Whereas in the latter it is common to generate text that can be searched against a vector database, the approach for structured data is often for the LLM to write and execute queries in a DSL, such as SQL. In this guide we'll go over the basic ways to create a Q&A system over tabular data in databases. We will cover implementations using both chains and agents. These systems will allow us to ask a question about the data in a database and get back a natural language answer. The main difference between the two is that our agent can query the database in a loop as many times as it needs to answer the question.\n",
    "\n",
    "## Security note\n",
    "Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. Make sure that your database connection permissions are always scoped as narrowly as possible for your chain/agent's needs. This will mitigate though not eliminate the risks of building a model-driven system. For more on general security best practices, see [here](https://python.langchain.com/v0.2/docs/security/).\n",
    "\n",
    "## Architecture\n",
    "At a high-level, the steps of these systems are:\n",
    "\n",
    "1. Convert question to DSL query: Model converts user input to a SQL query.\n",
    "2. Execute SQL query: Execute the query.\n",
    "3. Answer the question: Model responds to user input using the query results.\n",
    "\n",
    "Note that querying data in CSVs can follow a similar approach. See our [how-to guide on question-answering over CSV data](https://python.langchain.com/v0.2/docs/how_to/sql_csv/) for more detail.\n",
    "\n",
    "## Setup\n",
    "First, install the required packages and set environment variables:\n",
    "\n",
    "A non-comprehensive list of dependencies used in this examples are listed here\n",
    "```bash\n",
    "bs4==0.0.2\n",
    "langchain==0.2.1\n",
    "langchain-chroma==0.1.1\n",
    "langchain-community==0.2.1\n",
    "langchain-core==0.2.1\n",
    "langchain-openai==0.1.7\n",
    "langchain-text-splitters==0.2.0\n",
    "langchainhub==0.1.20\n",
    "langgraph==0.0.60\n",
    "langserve==0.2.1\n",
    "langsmith==0.1.63\n",
    "python-dotenv==1.0.1\n",
    "faiss-cpu==1.8.0.post1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28cab2e-455d-49e6-8661-cea223e01139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet  langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bfb5c6-88df-4d57-9148-c8d2b0a649d8",
   "metadata": {},
   "source": [
    "We will use an OpenAI model in this guide\n",
    "\n",
    "Langchain is also used for tracing\n",
    "\n",
    "### Setting credentials with python-dot-env\n",
    "Load credentials from a `.env` file and the [python-dotenv package](https://pypi.org/project/python-dotenv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b90af3-86e3-418c-9bfc-4ed0f6400cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv()\n",
    "assert os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "assert os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984289db-b4d3-4ac5-835b-93094859f373",
   "metadata": {},
   "source": [
    "### Install the Chinook database and SQLite3\n",
    "\n",
    "You will first need to install sqlite3\n",
    "```bash\n",
    "sudo apt-get install sqlite3\n",
    "```\n",
    "\n",
    "The below example will use a SQLite connection with Chinook database. Follow these installation steps to create Chinook.db in the same directory as this notebook:\n",
    "\n",
    "* Save [this file](https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql) as Chinook.sql\n",
    "* Run `sqlite3 Chinook.db`\n",
    "* Run `.read Chinook.sql`\n",
    "* Test `SELECT * FROM Artist LIMIT 10;`\n",
    "\n",
    "Now, `Chinhook.db` is in our directory and we can interface with it using the SQLAlchemy-driven `SQLDatabase` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870ff553-0f24-4db9-abbc-7509f7f65328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\") # Reads from file Chinook.db from the same directory\n",
    "\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb2bb9-fae6-41ce-bd57-a71aa87764cc",
   "metadata": {},
   "source": [
    "__API Reference__: [SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html)\n",
    "\n",
    "Great! We've got a SQL database that we can query. Now let's try hooking it up to an LLM.\n",
    "\n",
    "## Chains\n",
    "Chains (i.e., compositions of LangChain [Runnables](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)) support applications whose steps are predictable. We can create a simple chain that takes a question and does the following:\n",
    "\n",
    "* convert the question into a SQL query;\n",
    "* execute the query;\n",
    "* use the result to answer the original question.\n",
    "\n",
    "There are scenarios not supported by this arrangement. For example, this system will execute a SQL query for any user input-- even \"hello\". Importantly, as we'll see below, some questions require more than one query to answer. We will address these scenarios in the Agents section.\n",
    "\n",
    "### Convert question to SQL query\n",
    "The first step in a SQL chain or agent is to take the user input and convert it to a SQL query. LangChain comes with a built-in chain for this: [create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddf1167-2c0f-4509-9662-5b27f56dd59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81643c1-8b9c-46e4-a40e-5615cf3f869f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(\"EmployeeId\") AS \"TotalEmployees\" FROM \"Employee\"\\nLIMIT 1;'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"How many employees are there\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f19faf-0cc1-40cb-a63b-76206e297b21",
   "metadata": {},
   "source": [
    "API Reference: [create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\n",
    "\n",
    "We can execute the query to ensure it is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0556a3-6897-40da-bf97-686473ff1073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(8,)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e7b21-97a8-4fe8-89b2-2d8048898b2d",
   "metadata": {},
   "source": [
    "We can look at the [LangSmith trace](https://smith.langchain.com/public/c8fa52ea-be46-4829-bde2-52894970b830/r) to get a better understanding of what this chain is doing. We can also inspect the chain directly for its prompts. Looking at the prompt (below), we can see that it is:\n",
    "\n",
    "* Dialect-specific. In this case it references SQLite explicitly.\n",
    "* Has definitions for all the available tables.\n",
    "* Has three examples rows for each table.\n",
    "\n",
    "This technique is inspired by papers like [this](https://arxiv.org/pdf/2204.00498.pdf), which suggest showing examples rows and being explicit about tables improves performance. We can also inspect the full prompt like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11649915-6f31-4c62-923d-4e3a2adcd653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff1ade-32d9-4058-b44f-bd4a2265ed84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Execute SQL query\n",
    "Now that we've generated a SQL query, we'll want to execute it. This is __the most dangerous part of creating a SQL chain.__ Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
    "\n",
    "We can use the `QuerySQLDatabaseTool` to easily add query execution to our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85503ab2-f24c-43bf-a4d6-f221e31a81df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(8,)]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)    # Create a tool to query the DB with\n",
    "write_query = create_sql_query_chain(llm, db)  # Create a chain where the DB is read by the LLM to write queries\n",
    "chain = write_query | execute_query            # Create a chain where the written query is execute\n",
    "chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3d288-d8e6-4e2a-9086-0fc4bfb90975",
   "metadata": {
    "tags": []
   },
   "source": [
    "__API Reference__: [QuerySQLDataBaseTool](https://api.python.langchain.com/en/latest/tools/langchain_community.tools.sql_database.tool.QuerySQLDataBaseTool.html)\n",
    "\n",
    "### Answer the question\n",
    "Now that we've got a way to automatically generate and execute queries, we just need to combine the original question and SQL query result to generate a final answer. We can do this by passing question and result to the LLM once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c42ada03-a3d1-4bf5-acc9-aa11f599fae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are a total of 8 employees in the database.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ") # Create a Prompttemplate\n",
    "\n",
    "# Create a chain\n",
    "# the LLM writing a DB query\n",
    "# extract the query by key\n",
    "# Run the query\n",
    "chain = (\n",
    "    RunnablePassthrough \\\n",
    "        .assign(query=write_query) \\\n",
    "        .assign(\n",
    "        result=itemgetter(\"query\") \\\n",
    "        | execute_query                \n",
    "    )\n",
    "    | answer_prompt                    # Send the query to the PromptTemplate\n",
    "    | llm                              # Send the rendered Template the LLM\n",
    "    | StrOutputParser()                # StrOutputParser extracts only the MachineAnswer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0e737-ff96-4646-a5a6-e417f427c5dd",
   "metadata": {},
   "source": [
    "Let's review what is happening in the above LCEL. Suppose this chain is invoked.\n",
    "\n",
    "* After the first `RunnablePassthrough.assign`, we have a runnable with two elements:\n",
    "`{\"question\": question, \"query\": write_query.invoke(question)}` Where `write_query` will generate a SQL query in service of answering the question.\n",
    "* After the second R`unnablePassthrough.assign`, we have add a third element `\"result\"` that contains `execute_query.invoke(query)`, where query was computed in the previous step.\n",
    "* These three inputs are formatted into the prompt and passed into the LLM. The `StrOutputParser()` plucks out the string content of the output message.\n",
    "* Note that we are composing LLMs, tools, prompts, and other chains together, but because each implements the Runnable interface, their inputs and outputs can be tied together in a reasonable way.\n",
    "\n",
    "### Next steps\n",
    "For more complex query-generation, we may want to create few-shot prompts or add query-checking steps. For advanced techniques like this and more check out:\n",
    "\n",
    "* [Prompting strategies](https://python.langchain.com/v0.2/docs/how_to/sql_prompting/): Advanced prompt engineering techniques.\n",
    "* [Query checking](https://python.langchain.com/v0.2/docs/how_to/sql_query_checking/): Add query validation and error handling.\n",
    "* [Large databases](https://python.langchain.com/v0.2/docs/how_to/sql_large_db/): Techniques for working with large databases.\n",
    "\n",
    "## Agents\n",
    "LangChain has a SQL Agent which provides a more flexible way of interacting with SQL Databases than a chain. The main advantages of using the SQL Agent are:\n",
    "\n",
    "* It can answer questions based on the databases' schema as well as on the databases' content (like describing a specific table).\n",
    "* It can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
    "* It can query the database as many times as needed to answer the user question.\n",
    "* It will save tokens by only retrieving the schema from relevant tables.\n",
    "\n",
    "To initialize the agent we'll use the `SQLDatabaseToolkit` to create a bunch of tools:\n",
    "\n",
    "* Create and execute queries\n",
    "* Check query syntax\n",
    "* Retrieve table descriptions\n",
    "* ... and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527e6e53-1808-442f-8534-340ccdf54924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7fc7265f8b50>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7fc7265f8b50>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7fc7265f8b50>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7fc7265f8b50>, llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fc7249a4610>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fc7249ac350>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''), llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'query'], template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fc7249a4610>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fc7249ac350>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='')))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e4989-df7d-4881-8819-1ced89c3c562",
   "metadata": {},
   "source": [
    "__API Reference__: [SQLDatabaseToolkit](https://api.python.langchain.com/en/latest/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fef724-efe7-4d07-a6e0-968e0057de97",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "We will also want to create a system prompt for our agent. This will consist of instructions for how to behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed68ccfc-8b31-4ac8-8b03-dba95afeaef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "SQL_PREFIX = \"\"\"You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to tools for interacting with the database.\n",
    "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "Do NOT skip this step.\n",
    "Then you should query the schema of the most relevant tables.\"\"\"\n",
    "\n",
    "system_message = SystemMessage(content=SQL_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c449e2-287b-46a8-bd8b-7fccb92c4e02",
   "metadata": {},
   "source": [
    "__API Reference__: [SystemMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cff119-6671-4b87-8380-2876b95c4e31",
   "metadata": {},
   "source": [
    "### Initializing agent\n",
    "\n",
    "We will required the package __LangGraph__\n",
    "\n",
    "We will use a prebuilt [LangGraph](https://python.langchain.com/v0.2/docs/concepts/#langgraph) agent to build our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f5d851-a025-45ee-a042-4d3bec1c1854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Construct the Agent\n",
    "agent_executor = create_react_agent(llm,    # Can access LLM\n",
    "                                    tools,  # Can access tools\n",
    "                                    messages_modifier=system_message) # Messages will always be modified with System Message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a8dc6-c3ed-4261-9d48-4889d114a1fc",
   "metadata": {},
   "source": [
    "__API Reference__: [HumanMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html)\n",
    "\n",
    "Consider how the agent responds to the below question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed3f5839-f431-466e-a9d3-2855d84dc839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_VoSFC89YoaOo242G3cRDGCKk', 'function': {'arguments': '{\"table_names\":\"customers\"}', 'name': 'sql_db_schema'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 557, 'total_tokens': 573}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3ddbb967-cb28-4bb4-a738-11001cbf8773-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'customers'}, 'id': 'call_VoSFC89YoaOo242G3cRDGCKk'}], usage_metadata={'input_tokens': 557, 'output_tokens': 16, 'total_tokens': 573})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"Error: table_names {'customers'} not found in database\", name='sql_db_schema', tool_call_id='call_VoSFC89YoaOo242G3cRDGCKk')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sJlxEfkyhjRPyETZa8cZjX8p', 'function': {'arguments': '{}', 'name': 'sql_db_list_tables'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 593, 'total_tokens': 605}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-febccafb-0104-4cc5-8e90-971f2a9d851f-0', tool_calls=[{'name': 'sql_db_list_tables', 'args': {}, 'id': 'call_sJlxEfkyhjRPyETZa8cZjX8p'}], usage_metadata={'input_tokens': 593, 'output_tokens': 12, 'total_tokens': 605})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', name='sql_db_list_tables', tool_call_id='call_sJlxEfkyhjRPyETZa8cZjX8p')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1XA4ak68HzvminUYOBdaFMtY', 'function': {'arguments': '{\"query\":\"SELECT c.Country, SUM(i.Total) as Total_Spent \\\\nFROM Customer c \\\\nJOIN Invoice i ON c.CustomerId = i.CustomerId \\\\nGROUP BY c.Country \\\\nORDER BY Total_Spent DESC \\\\nLIMIT 1\"}', 'name': 'sql_db_query'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 638, 'total_tokens': 701}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d0331891-c079-4d76-9b99-36b4cb604c5c-0', tool_calls=[{'name': 'sql_db_query', 'args': {'query': 'SELECT c.Country, SUM(i.Total) as Total_Spent \\nFROM Customer c \\nJOIN Invoice i ON c.CustomerId = i.CustomerId \\nGROUP BY c.Country \\nORDER BY Total_Spent DESC \\nLIMIT 1'}, 'id': 'call_1XA4ak68HzvminUYOBdaFMtY'}], usage_metadata={'input_tokens': 638, 'output_tokens': 63, 'total_tokens': 701})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"[('USA', 523.0600000000003)]\", name='sql_db_query', tool_call_id='call_1XA4ak68HzvminUYOBdaFMtY')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='Customers from the USA spent the most, with a total amount spent of $523.06.', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 723, 'total_tokens': 743}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e78e5e1d-7f72-43b3-bfe4-05fbaafdc5fb-0', usage_metadata={'input_tokens': 723, 'output_tokens': 20, 'total_tokens': 743})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in agent_executor.stream(                                                          # Streaming output\n",
    "    {\"messages\": [HumanMessage(content=\"Which country's customers spent the most?\")]}    # dict with messages, one of which is HumanMessage\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9abd6-523d-40d6-a7c6-4a57fa1cfab6",
   "metadata": {},
   "source": [
    "Note that the agent executes multiple queries until it has the information it needs:\n",
    "\n",
    "List available tables;\n",
    "1. Retrieves the schema for three tables;\n",
    "2. Queries multiple of the tables via a join operation.\n",
    "3. The agent is then able to use the result of the final query to generate an answer to the original question.\n",
    "\n",
    "The agent can similarly handle qualitative questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b0ca7f3-310c-4f70-be15-65ed18906592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bHaXSqC6J6IdnTjlxiq3ZeN0', 'function': {'arguments': '{\"table_names\":\"playlisttrack\"}', 'name': 'sql_db_schema'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 554, 'total_tokens': 571}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-20c5cfc4-cf13-4137-82bc-b58309aaed0e-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'playlisttrack'}, 'id': 'call_bHaXSqC6J6IdnTjlxiq3ZeN0'}], usage_metadata={'input_tokens': 554, 'output_tokens': 17, 'total_tokens': 571})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"Error: table_names {'playlisttrack'} not found in database\", name='sql_db_schema', tool_call_id='call_bHaXSqC6J6IdnTjlxiq3ZeN0')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='I apologize, it seems there was an error in retrieving the schema for the playlisttrack table. Let me try again to get the description of the playlisttrack table.', additional_kwargs={'tool_calls': [{'id': 'call_j2X9aNb8Jsmzql3aZrjy6gN8', 'function': {'arguments': '{}', 'name': 'sql_db_list_tables'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 592, 'total_tokens': 638}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea62c725-631d-409c-b5bb-4298b62c7ce2-0', tool_calls=[{'name': 'sql_db_list_tables', 'args': {}, 'id': 'call_j2X9aNb8Jsmzql3aZrjy6gN8'}], usage_metadata={'input_tokens': 592, 'output_tokens': 46, 'total_tokens': 638})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', name='sql_db_list_tables', tool_call_id='call_j2X9aNb8Jsmzql3aZrjy6gN8')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_onqw335MnYKmBRmxhPhh4C6V', 'function': {'arguments': '{\"table_names\":\"PlaylistTrack\"}', 'name': 'sql_db_schema'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 674, 'total_tokens': 691}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91f13c83-813f-4b5a-8032-f17c28e0efb7-0', tool_calls=[{'name': 'sql_db_schema', 'args': {'table_names': 'PlaylistTrack'}, 'id': 'call_onqw335MnYKmBRmxhPhh4C6V'}], usage_metadata={'input_tokens': 674, 'output_tokens': 17, 'total_tokens': 691})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='\\nCREATE TABLE \"PlaylistTrack\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from PlaylistTrack table:\\nPlaylistId\\tTrackId\\n1\\t3402\\n1\\t3389\\n1\\t3390\\n*/', name='sql_db_schema', tool_call_id='call_onqw335MnYKmBRmxhPhh4C6V')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='The `PlaylistTrack` table has the following schema:\\n- PlaylistId: INTEGER (NOT NULL)\\n- TrackId: INTEGER (NOT NULL)\\n\\nIt is a mapping table with a composite primary key on PlaylistId and TrackId. It has foreign key constraints referencing the Playlist table on PlaylistId and the Track table on TrackId.\\n\\nHere are 3 sample rows from the `PlaylistTrack` table:\\n1. PlaylistId: 1, TrackId: 3402\\n2. PlaylistId: 1, TrackId: 3389\\n3. PlaylistId: 1, TrackId: 3390', response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 804, 'total_tokens': 929}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4fd0874f-b571-4d07-af62-ca23eb5ccb1b-0', usage_metadata={'input_tokens': 804, 'output_tokens': 125, 'total_tokens': 929})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Describe the playlisttrack table\")]}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3e34e-c9d3-436b-b80c-0bd7700e7116",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dealing with high-cardinality columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa2559d-b777-4791-8a7c-1b489220c855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Green Day', 'Ozzy Osbourne', 'Emanuel Ax, Eugene Ormandy & Philadelphia Orchestra', 'Pedro Lu√≠s & A Parede', 'Simply Red']\n",
      "['Minha Hist√≥ria', 'Santana Live', 'Battlestar Galactica, Season', 'Allegri: Miserere', 'Bach: Goldberg Variations']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "\n",
    "def query_as_list(db, query):\n",
    "    res = db.run(query)\n",
    "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
    "    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]\n",
    "    return list(set(res))\n",
    "\n",
    "\n",
    "artists = query_as_list(db, \"SELECT Name FROM Artist\")  # A list of Artist names, these are proper nouns\n",
    "print(artists[:5])\n",
    "\n",
    "albums = query_as_list(db, \"SELECT Title FROM Album\")  # A list of Album names, these are proper nouns\n",
    "print(albums[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3943cf5-47cf-4470-9d44-536f8f7c1f22",
   "metadata": {},
   "source": [
    "Using this function, we can create a retriever tool that the agent can execute at its discretion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c995830b-6504-4e3a-83f4-5ce3594a13f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_db = FAISS.from_texts(artists + albums,\n",
    "                             OpenAIEmbeddings()) # A VectorDB built from the list of artists and albums, with OpenAI embeddings\n",
    "\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 5}) # A retriever that gets the top 5 values form the vector DB\n",
    "\n",
    "\n",
    "description = \"\"\"Use to look up values to filter on. Input is an approximate spelling of the proper noun, output is \\\n",
    "valid proper nouns. Use the noun most similar to the search.\"\"\"\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"search_proper_nouns\",\n",
    "    description=description,\n",
    ") # A tool built from the vector_db retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ad8ee-900e-4fe4-8413-e72b7b88082a",
   "metadata": {},
   "source": [
    "__API Reference__: [create_retriever_tool](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.create_retriever_tool.html) | [FAISS](https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) | [OpenAIEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)\n",
    "\n",
    "Let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a77f2b00-bc6d-45f9-a7b3-6543f1b9b890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice In Chains\n",
      "\n",
      "Alanis Morissette\n",
      "\n",
      "Pearl Jam\n",
      "\n",
      "Pearl Jam\n",
      "\n",
      "Audioslave\n"
     ]
    }
   ],
   "source": [
    "print(retriever_tool.invoke(\"Alice Chains\")) # Return the top 5 nouns which match \"Alice Chains\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5db73-fe33-4bc6-b9bc-733b551beb1a",
   "metadata": {},
   "source": [
    "This way, if the agent determines it needs to write a filter based on an artist along the lines of \"Alice Chains\", it can first use the retriever tool to observe relevant values of a column.\n",
    "\n",
    "Putting this together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "400c67b2-3296-4b09-9859-82cd1d90174a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system = \"\"\"You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to tools for interacting with the database.\n",
    "Only use the given tools. Only use the information returned by the tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "You have access to the following tables: {table_names}\n",
    "\n",
    "If you need to filter on a proper noun, you must ALWAYS first look up the filter value using the \"search_proper_nouns\" tool!\n",
    "Do not try to guess at the proper name - use this function to find similar ones.\"\"\".format(\n",
    "    table_names=db.get_usable_table_names() # Retrieve table names from the DB\n",
    ")\n",
    "\n",
    "system_message = SystemMessage(content=system) # Construct the System Message\n",
    "\n",
    "tools.append(retriever_tool)                   # Add the retriever tool to the tools list\n",
    "\n",
    "agent = create_react_agent(llm,\n",
    "                           tools,\n",
    "                           messages_modifier=system_message) # Construct the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4e5dcc3-2851-4e5d-9b11-c6f50fc2c283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CojheqSBN0OOCBUrlxXzx22U', 'function': {'arguments': '{\"query\":\"alis in chain\"}', 'name': 'search_proper_nouns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 736, 'total_tokens': 755}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-21ea5d58-34f4-4b67-a9b0-602e3f30b2cb-0', tool_calls=[{'name': 'search_proper_nouns', 'args': {'query': 'alis in chain'}, 'id': 'call_CojheqSBN0OOCBUrlxXzx22U'}], usage_metadata={'input_tokens': 736, 'output_tokens': 19, 'total_tokens': 755})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='Alice In Chains\\n\\nAisha Duo\\n\\nXis\\n\\nDa Lama Ao Caos\\n\\nA-Sides', name='search_proper_nouns', tool_call_id='call_CojheqSBN0OOCBUrlxXzx22U')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KMpcqOZNSrGDkxrL0bsomitm', 'function': {'arguments': '{\"query\":\"SELECT COUNT(Album.AlbumId) AS Number_of_Albums\\\\nFROM Album\\\\nJOIN Artist ON Album.ArtistId = Artist.ArtistId\\\\nWHERE Artist.Name = \\'Alice In Chains\\'\"}', 'name': 'sql_db_query'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 786, 'total_tokens': 840}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c1c32ecb-7a1c-4132-ac9b-cd8af2a15c98-0', tool_calls=[{'name': 'sql_db_query', 'args': {'query': \"SELECT COUNT(Album.AlbumId) AS Number_of_Albums\\nFROM Album\\nJOIN Artist ON Album.ArtistId = Artist.ArtistId\\nWHERE Artist.Name = 'Alice In Chains'\"}, 'id': 'call_KMpcqOZNSrGDkxrL0bsomitm'}], usage_metadata={'input_tokens': 786, 'output_tokens': 54, 'total_tokens': 840})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[(1,)]', name='sql_db_query', tool_call_id='call_KMpcqOZNSrGDkxrL0bsomitm')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='Alice In Chains has 1 album.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 853, 'total_tokens': 862}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ea999a74-1ed8-407a-a8f4-91e0efea5e9a-0', usage_metadata={'input_tokens': 853, 'output_tokens': 9, 'total_tokens': 862})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"How many albums does alis in chain have?\")]} # Note the typo\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5168ff6-d18d-4055-b4a3-38ea93015644",
   "metadata": {},
   "source": [
    "As we can see, the agent used the `search_proper_nouns` tool in order to check how to correctly query the database for this specific artist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 for LLM",
   "language": "python",
   "name": "llm-python-3-11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
