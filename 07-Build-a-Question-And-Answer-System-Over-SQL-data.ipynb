{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7035ad-cfea-4c2e-9cfe-c37942d8922d",
   "metadata": {},
   "source": [
    "# Build a Question and Answer system over SQL data\n",
    "Enabling a LLM system to query structured data can be qualitatively different from unstructured text data. Whereas in the latter it is common to generate text that can be searched against a vector database, the approach for structured data is often for the LLM to write and execute queries in a DSL, such as SQL. In this guide we'll go over the basic ways to create a Q&A system over tabular data in databases. We will cover implementations using both chains and agents. These systems will allow us to ask a question about the data in a database and get back a natural language answer. The main difference between the two is that our agent can query the database in a loop as many times as it needs to answer the question.\n",
    "\n",
    "## Security note\n",
    "Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. Make sure that your database connection permissions are always scoped as narrowly as possible for your chain/agent's needs. This will mitigate though not eliminate the risks of building a model-driven system. For more on general security best practices, see [here](https://python.langchain.com/v0.2/docs/security/).\n",
    "\n",
    "## Architecture\n",
    "At a high-level, the steps of these systems are:\n",
    "\n",
    "1. Convert question to DSL query: Model converts user input to a SQL query.\n",
    "2. Execute SQL query: Execute the query.\n",
    "3. Answer the question: Model responds to user input using the query results.\n",
    "\n",
    "Note that querying data in CSVs can follow a similar approach. See our [how-to guide on question-answering over CSV data](https://python.langchain.com/v0.2/docs/how_to/sql_csv/) for more detail.\n",
    "\n",
    "## Setup\n",
    "First, install the required packages and set environment variables:\n",
    "\n",
    "A non-comprehensive list of dependencies used in this examples are listed here\n",
    "```bash\n",
    "bs4==0.0.2\n",
    "langchain==0.2.1\n",
    "langchain-chroma==0.1.1\n",
    "langchain-community==0.2.1\n",
    "langchain-core==0.2.1\n",
    "langchain-openai==0.1.7\n",
    "langchain-text-splitters==0.2.0\n",
    "langchainhub==0.1.20\n",
    "langgraph==0.0.60\n",
    "langserve==0.2.1\n",
    "langsmith==0.1.63\n",
    "python-dotenv==1.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28cab2e-455d-49e6-8661-cea223e01139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet  langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bfb5c6-88df-4d57-9148-c8d2b0a649d8",
   "metadata": {},
   "source": [
    "We will use an OpenAI model in this guide\n",
    "\n",
    "Langchain is also used for tracing\n",
    "\n",
    "### Setting credentials with python-dot-env\n",
    "Load credentials from a `.env` file and the [python-dotenv package](https://pypi.org/project/python-dotenv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b90af3-86e3-418c-9bfc-4ed0f6400cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv()\n",
    "assert os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "assert os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984289db-b4d3-4ac5-835b-93094859f373",
   "metadata": {},
   "source": [
    "### Install the Chinook database and SQLite3\n",
    "\n",
    "You will first need to install sqlite3\n",
    "```bash\n",
    "sudo apt-get install sqlite3\n",
    "```\n",
    "\n",
    "The below example will use a SQLite connection with Chinook database. Follow these installation steps to create Chinook.db in the same directory as this notebook:\n",
    "\n",
    "* Save [this file](https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql) as Chinook.sql\n",
    "* Run `sqlite3 Chinook.db`\n",
    "* Run `.read Chinook.sql`\n",
    "* Test `SELECT * FROM Artist LIMIT 10;`\n",
    "\n",
    "Now, `Chinhook.db` is in our directory and we can interface with it using the SQLAlchemy-driven `SQLDatabase` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870ff553-0f24-4db9-abbc-7509f7f65328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\") # Reads from file Chinook.db from the same directory\n",
    "\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb2bb9-fae6-41ce-bd57-a71aa87764cc",
   "metadata": {},
   "source": [
    "__API Reference__: [SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html)\n",
    "\n",
    "Great! We've got a SQL database that we can query. Now let's try hooking it up to an LLM.\n",
    "\n",
    "## Chains\n",
    "Chains (i.e., compositions of LangChain [Runnables](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)) support applications whose steps are predictable. We can create a simple chain that takes a question and does the following:\n",
    "\n",
    "* convert the question into a SQL query;\n",
    "* execute the query;\n",
    "* use the result to answer the original question.\n",
    "\n",
    "There are scenarios not supported by this arrangement. For example, this system will execute a SQL query for any user input-- even \"hello\". Importantly, as we'll see below, some questions require more than one query to answer. We will address these scenarios in the Agents section.\n",
    "\n",
    "### Convert question to SQL query\n",
    "The first step in a SQL chain or agent is to take the user input and convert it to a SQL query. LangChain comes with a built-in chain for this: [create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddf1167-2c0f-4509-9662-5b27f56dd59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81643c1-8b9c-46e4-a40e-5615cf3f869f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(\"EmployeeId\") AS \"TotalEmployees\" FROM \"Employee\"\\nLIMIT 1;'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"How many employees are there\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f19faf-0cc1-40cb-a63b-76206e297b21",
   "metadata": {},
   "source": [
    "API Reference: [create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\n",
    "\n",
    "We can execute the query to ensure it is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0556a3-6897-40da-bf97-686473ff1073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(8,)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e7b21-97a8-4fe8-89b2-2d8048898b2d",
   "metadata": {},
   "source": [
    "We can look at the [LangSmith trace](https://smith.langchain.com/public/c8fa52ea-be46-4829-bde2-52894970b830/r) to get a better understanding of what this chain is doing. We can also inspect the chain directly for its prompts. Looking at the prompt (below), we can see that it is:\n",
    "\n",
    "* Dialect-specific. In this case it references SQLite explicitly.\n",
    "* Has definitions for all the available tables.\n",
    "* Has three examples rows for each table.\n",
    "\n",
    "This technique is inspired by papers like [this](https://arxiv.org/pdf/2204.00498.pdf), which suggest showing examples rows and being explicit about tables improves performance. We can also inspect the full prompt like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11649915-6f31-4c62-923d-4e3a2adcd653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803fcd2-d6a6-4d09-b222-9f1c6e3a5d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 for LLM",
   "language": "python",
   "name": "llm-python-3-11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
